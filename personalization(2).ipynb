{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136e5216",
   "metadata": {},
   "source": [
    "In this notebook, we'll create a dataset within Amazon Personalize and import relevant data sources, including user interactions and product metadata. We'll then choose an appropriate recipe based on our recommendation goals, such as user-personalization. After creating a solution and training the model using the selected recipe and dataset,  we'll leverage the deployed solution to produce personalized product recommendations tailored to individual users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23310a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "%store -r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edffb4b",
   "metadata": {},
   "source": [
    "***Creating a Dataset Group for Personalize***\n",
    "\n",
    "Configure the AWS SDK to interact with Amazon Personalize, then creates a new dataset group named \"personalize-product-recommendations.\" Capture the ARN of the created dataset group. Sets a maximum runtime of 3 hours and continuously polls the status of the dataset group creation in Amazon Personalize. Check if the status of the dataset group is \"ACTIVE\" or \"CREATE FAILED\" every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset\n",
    "\n",
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-product-recommendations\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c85cdb",
   "metadata": {},
   "source": [
    "***Creating Interactions Schema and Dataset***\n",
    "\n",
    "Define an interactions schema for Amazon Personalize, specifying fields for TIMESTAMP, USER_ID, ITEM_ID, and ITEM_NAME. Create the schema in Personalize and retrieves its ARN. Next, we must create an interactions dataset using this schema and associates it with the previously created dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d47454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create interactions schema\n",
    "\n",
    "\n",
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-product-recommendations-interactions\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interaction_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-product-recommendations-ints\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interaction_schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8378b",
   "metadata": {},
   "source": [
    "***Creating Users Schema and Dataset***\n",
    "\n",
    "Define a schema for user data in Amazon Personalize, specifying fields such as TIMESTAMP, product_id, product_name, rating, AGE, USER_ID, user_name, review_id, and review_title. Next, we must create a users dataset using the defined schema and associate it with the existing dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f562e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user schema\n",
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RATING\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AGE\",\n",
    "            \"type\": \"int\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USERNAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"REVIEW_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"REVIEW_TITLE\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "create_users_schema_response = personalize.create_schema(\n",
    "    name='personalize-user-recommendations-items',\n",
    "    schema=json.dumps(users_schema)\n",
    ")\n",
    "\n",
    "users_schema_arn = create_users_schema_response['schemaArn']\n",
    "print(json.dumps(create_users_schema_response, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "dataset_type = \"USERS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-product-recommendations-users1234\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = users_schema_arn\n",
    ")\n",
    "\n",
    "\n",
    "users_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4950b",
   "metadata": {},
   "source": [
    "***Creating Items Schema and Dataset***\n",
    "\n",
    "Define a schema for item data in Amazon Personalize, specifying fields such as CREATION_TIMESTAMP, ITEM_ID, product_name, category, rating_count, and DESCRIPTION. Next, an items dataset is created using the defined schema and associated with the existing dataset group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019dcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"CREATION_TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": [\"null\", \"string\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATEGORY\",\n",
    "            \"type\": [\"null\", \"string\"],\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RATING_COUNT\",\n",
    "            \"type\": [\"null\", \"string\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DESCRIPTION\",\n",
    "            \"type\": [\"null\", \"string\"],\n",
    "            \"textual\": True\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name=\"personalize-product-recommendations-items\",\n",
    "    schema=json.dumps(items_schema)\n",
    ")\n",
    "\n",
    "items_schema_arn = create_schema_response['schemaArn']S\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "dataset_type = \"ITEMS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name=\"personalize-product-recommendations-items-dataset\",\n",
    "    datasetType=dataset_type,\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    schemaArn=items_schema_arn\n",
    ")\n",
    "\n",
    "items_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5697d6",
   "metadata": {},
   "source": [
    "***Configure S3 bucket and IAM role for Personalize***\n",
    "\n",
    "Allow AWS Personalize to have access to the data stored in the initial S3 bucket. Next,create an IAM role which defines the trust policy when using Personalize as a service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc7326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'personalizeproductreviewdata'\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20208b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRolePOC\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d70c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction dataset import\n",
    "\n",
    "\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-product-import3\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user dataset import\n",
    "\n",
    "user_filename = 'user_data.csv'\n",
    "\n",
    "create_user_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName=\"personalize-user-import3\",\n",
    "    datasetArn=users_dataset_arn,\n",
    "    dataSource={\n",
    "        \"dataLocation\": f\"s3://{bucket_name}/{user_filename}\"\n",
    "    },\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "user_dataset_import_job_arn = create_user_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_user_dataset_import_job_response, indent=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbed94d",
   "metadata": {},
   "source": [
    "***Importing Datasets into Personalize***\n",
    "\n",
    "Perform dataset import jobs for the interactions dataset, the user dataset, and the item dataset. Each import job specifies the dataset ARN, the location of the data in an S3 bucket, and the IAM role ARN that grants Personalize access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83de239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item dataset import\n",
    "\n",
    "\n",
    "item_filename = 'product_data.csv'\n",
    "\n",
    "create_items_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName=\"personalize-items-import3\",\n",
    "    datasetArn=items_dataset_arn,\n",
    "    dataSource={\n",
    "        \"dataLocation\": f\"s3://{bucket_name}/{item_filename}\"\n",
    "    },\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "items_dataset_import_job_arn = create_items_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_items_dataset_import_job_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedb645",
   "metadata": {},
   "source": [
    "***Monitoring Dataset Import in Amazon Personalize***\n",
    "\n",
    "We monitor the progress of the item,user,and interaction dataset import job in Amazon Personalize. Set a maximum wait time of 6 hours for the job to complete. The code then enters a loop that checks the status of the dataset import job every minute using the describe_dataset_import_job API call. If the status is \"ACTIVE\", indicating that the job has completed successfully, the loop is broken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating interaction datajob\n",
    "\n",
    "#%%time\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user datajob\n",
    "\n",
    "max_time = time.time() + 6 * 60 * 60  # 6 hours max wait time\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn=user_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(f\"DatasetImportJob: {status}\")\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item datajob\n",
    "\n",
    "\n",
    "max_time = time.time() + 6 * 60 * 60  # 6 hours max wait time\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn=items_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(f\"DatasetImportJob: {status}\")\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d824510",
   "metadata": {},
   "source": [
    "***Creating Solution and Solution Version***\n",
    "\n",
    "We will be using the \"aws-user-personalization\" recipe which is designed for user personalization tasks. It is a powerful tool for creating personalized recommendations for users based on their interactions with items in a dataset. The recipe uses the User-Personalized Ranking (UPR) algorithm, which is a variation of the Weighted Matrix Factorization (WMF) algorithm. The UPR algorithm is optimized for generating personalized recommendations by focusing on the relative preferences of users rather than their absolute preferences. After choosing the recipe, we must create a solution which is associated to our previous dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d276648",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-soln-user-personalization2\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ee7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fda2de",
   "metadata": {},
   "source": [
    "***Creating and Monitoring Personalize Campaign***\n",
    "\n",
    "We create a campaign in order to serve real-time personalized recommendations to users. The campaign ARN returned by the create_campaign API can be used to invoke the Personalize Runtime API to get recommendations for a specific user. We can also configure the service settings to set a minimum provisioned transactions per second (TPS) for the campaign, which determines the minimum level of traffic the campaign can handle. We also configure the item exploration settings, which can be used to balance exploration of new items versus exploitation of known user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183883c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-recs\",\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 1,\n",
    "    campaignConfig = {\n",
    "        \"itemExplorationConfig\": {\n",
    "            \"explorationWeight\": \"0.3\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e55af",
   "metadata": {},
   "source": [
    "***Generating and Saving Personalize Recommendations***\n",
    "\n",
    "We first load the interactions data and creates a mapping of item IDs to item names. Next, we use the get_recommendations API from the Personalize Runtime to retrieve personalized recommendations for the selected user, based on the campaign created earlier. The recommended item IDs are then mapped to their corresponding item names using the previously created mapping.Lastly, we iterate through all unique user IDs in the interactions data, retrieving personalized recommendations for each user and storing them in a list of dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59691b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the interactions data to print out user recs\n",
    "\n",
    "items_map = dict(zip(interactions_df['ITEM_ID'].astype(str), interactions_df['ITEM_NAME']))\n",
    "user_id, item_id = interactions_df[['USER_ID', 'ITEM_ID']].sample().values[0]\n",
    "\n",
    "print(f\"User Id: {user_id.split(',')[0]}\")\n",
    "\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn=campaign_arn,\n",
    "    userId=str(user_id),\n",
    ")\n",
    "\n",
    "# Extract recommended item IDs from the response\n",
    "recommendation_list = [item['itemId'] for item in get_recommendations_response['itemList']]\n",
    "recommendation_names = [items_map.get(item_id, 'Unknown') for item_id in recommendation_list]\n",
    "\n",
    "\n",
    "recommendations_df = pd.DataFrame(recommendation_names, columns=['Recommended_Item'])\n",
    "recommendations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51abb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = interactions_df['USER_ID'].unique()\n",
    "\n",
    "all_recommendations = []\n",
    "\n",
    "for user_id in user_ids:\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn=campaign_arn,\n",
    "        userId=str(user_id)\n",
    "    )\n",
    "    \n",
    "    recommendation_list = [item['itemId'] for item in get_recommendations_response['itemList']]\n",
    "    \n",
    "    recommendation_names = [items_map.get(item_id, 'Unknown') for item_id in recommendation_list]\n",
    "    \n",
    "    # Aggregate recommendations, limiting to 5 per user\n",
    "    all_recommendations.append({'User ID': user_id, 'Recommended_Items': recommendation_names[:5]})\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = 'user_recommendations.csv'\n",
    "recommendations_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Recommendations DataFrame saved to {csv_filename}\")\n",
    "\n",
    "print(recommendations_df['Recommended_Items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51efd8",
   "metadata": {},
   "source": [
    "***Storing Personalized Recommendations in Amazon DynamoDB***\n",
    "\n",
    "We create DynamoDB table named if it doesn't already exist, and then insert the personalized recommendations generated in the previous step into the table. The recommendations are stored with the user ID as the hash key and as a dictionary, allowing for efficient retrieval of recommendations for specific users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.client('dynamodb')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "table_name = 'user_recommendations4'\n",
    "\n",
    "existing_tables = dynamodb.list_tables()['TableNames']\n",
    "if table_name not in existing_tables:\n",
    "    dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'User ID',\n",
    "                'KeyType': 'HASH'\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'User ID',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        BillingMode='PAY_PER_REQUEST'\n",
    "    )\n",
    "\n",
    "    print(f\"Table {table_name} creation initiated. Waiting for table to become active...\")\n",
    "    waiter = dynamodb.get_waiter('table_exists')\n",
    "    waiter.wait(TableName=table_name)\n",
    "    print(f\"Table {table_name} created successfully.\")\n",
    "else:\n",
    "    print(f\"Table {table_name} already exists.\")\n",
    "\n",
    "# Insert recommendations into DynamoDB\n",
    "table = dynamodb_resource.Table(table_name)\n",
    "with table.batch_writer() as batch:\n",
    "    for index, row in recommendations_df.iterrows():\n",
    "        user_id = str(row['User ID'])\n",
    "        recommended_items = row['Recommended_Items']\n",
    "        \n",
    "        try:\n",
    "            batch.put_item(\n",
    "                Item={\n",
    "                    'User ID': user_id,\n",
    "                    'Recommended_Items': recommended_items  # directly store the list\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting recommendation for user {user_id}: {e}\")\n",
    "\n",
    "print(\"All recommendations inserted into DynamoDB table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store bucket_name\n",
    "%store recommendations_df\n",
    "%store interactions_dataset_arn\n",
    "%store users_dataset_arn\n",
    "%store items_dataset_arn\n",
    "%store role_name\n",
    "%store role_arn\n",
    "%store interactions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf23795",
   "metadata": {},
   "source": [
    "# Implementing Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e5216",
   "metadata": {},
   "source": [
    "In this notebook, we'll create a dataset within Amazon Personalize and import relevant data sources, including user interactions and product metadata. We'll then choose an appropriate recipe based on our recommendation goals, such as user-personalization. After creating a solution and training the model using the selected recipe and dataset,  we'll leverage the deployed solution to produce personalized product recommendations tailored to individual users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23310a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "%store -r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edffb4b",
   "metadata": {},
   "source": [
    "***Creating a Dataset Group for Personalize***\n",
    "\n",
    "Configure the AWS SDK to interact with Amazon Personalize, then creates a new dataset group named \"personalize-product-recommendations.\" Capture the ARN of the created dataset group. Sets a maximum runtime of 3 hours and continuously polls the status of the dataset group creation in Amazon Personalize. Check if the status of the dataset group is \"ACTIVE\" or \"CREATE FAILED\" every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset\n",
    "\n",
    "# Configure the SDK to Personalize:\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-product-recommendations\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80911c",
   "metadata": {},
   "source": [
    "# Creating Schema and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c85cdb",
   "metadata": {},
   "source": [
    "***Creating Interactions Schema and Dataset***\n",
    "\n",
    "Define an interactions schema for Amazon Personalize, specifying fields for TIMESTAMP, USER_ID, ITEM_ID, and ITEM_NAME. Create the schema in Personalize and retrieves its ARN. Next, we must create an interactions dataset using this schema and associates it with the previously created dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d47454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create interactions schema\n",
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USERNAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"SENTIMENT\",\n",
    "          \"type\": \"string\"\n",
    "        }\n",
    "        \n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-product-recommendations-interactions3786\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interaction_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-product-recommendations-ints-dataset\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interaction_schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8378b",
   "metadata": {},
   "source": [
    "***Creating Users Schema and Dataset***\n",
    "\n",
    "Define a schema for user data in Amazon Personalize, specifying fields such as TIMESTAMP, product_id, product_name, rating, AGE, USER_ID, user_name, review_id, and review_title. Next, we must create a users dataset using the defined schema and associate it with the existing dataset group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f562e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user schema\n",
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RATING\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"AGE\",\n",
    "            \"type\": \"int\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"USERNAME\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"REVIEW_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"REVIEW_TITLE\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "create_users_schema_response = personalize.create_schema(\n",
    "    name='personalize-user-recommendations-users',\n",
    "    schema=json.dumps(users_schema)\n",
    ")\n",
    "\n",
    "users_schema_arn = create_users_schema_response['schemaArn']\n",
    "print(json.dumps(create_users_schema_response, indent=2))\n",
    "\n",
    "\n",
    "\n",
    "dataset_type = \"USERS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-product-recommendations-users-dataset\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = users_schema_arn\n",
    ")\n",
    "\n",
    "\n",
    "users_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4950b",
   "metadata": {},
   "source": [
    "***Creating Items Schema and Dataset***\n",
    "\n",
    "Define a schema for item data in Amazon Personalize, specifying fields such as CREATION_TIMESTAMP, ITEM_ID, product_name, category, rating_count, and DESCRIPTION. Next, an items dataset is created using the defined schema and associated with the existing dataset group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019dcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"CREATION_TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"PRODUCT_NAME\",\n",
    "            \"type\": [\"null\", \"string\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATEGORY\",\n",
    "            \"type\": [\"null\", \"string\"],\n",
    "            \"categorical\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RATING_COUNT\",\n",
    "            \"type\": [\"null\", \"string\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"DESCRIPTION\",\n",
    "            \"type\": [\"null\", \"string\"],\n",
    "            \"textual\": True\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name=\"personalize-product-recommendations-items\",\n",
    "    schema=json.dumps(items_schema)\n",
    ")\n",
    "\n",
    "items_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "dataset_type = \"ITEMS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name=\"personalize-product-recommendations-items-dataset\",\n",
    "    datasetType=dataset_type,\n",
    "    datasetGroupArn=dataset_group_arn,\n",
    "    schemaArn=items_schema_arn\n",
    ")\n",
    "\n",
    "items_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32467a",
   "metadata": {},
   "source": [
    "## Implementation of IAM Roles and Policies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5697d6",
   "metadata": {},
   "source": [
    "***Configure S3 bucket and IAM role for Personalize***\n",
    "\n",
    "Allow AWS Personalize to have access to the data stored in the initial S3 bucket. Next,create an IAM role which defines the trust policy when using Personalize as a service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc7326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20208b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRolePOC\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbed94d",
   "metadata": {},
   "source": [
    "## Importing Datasets into Personalize\n",
    "\n",
    "Perform dataset import jobs for the interactions dataset, the user dataset, and the item dataset. Each import job specifies the dataset ARN, the location of the data in an S3 bucket, and the IAM role ARN that grants Personalize access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d70c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction dataset import\n",
    "\n",
    "\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-product-import\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user dataset import\n",
    "\n",
    "user_filename = 'user_data.csv'\n",
    "\n",
    "create_user_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName=\"personalize-user-import\",\n",
    "    datasetArn=users_dataset_arn,\n",
    "    dataSource={\n",
    "        \"dataLocation\": f\"s3://{bucket_name}/{user_filename}\"\n",
    "    },\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "user_dataset_import_job_arn = create_user_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_user_dataset_import_job_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83de239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item dataset import\n",
    "\n",
    "\n",
    "item_filename = 'product_data.csv'\n",
    "\n",
    "create_items_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName=\"personalize-items-import\",\n",
    "    datasetArn=items_dataset_arn,\n",
    "    dataSource={\n",
    "        \"dataLocation\": f\"s3://{bucket_name}/{item_filename}\"\n",
    "    },\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "items_dataset_import_job_arn = create_items_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_items_dataset_import_job_response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedb645",
   "metadata": {},
   "source": [
    "***Monitoring Dataset Import in Amazon Personalize***\n",
    "\n",
    "We monitor the progress of the item,user,and interaction dataset import job in Amazon Personalize. Set a maximum wait time of 6 hours for the job to complete. The code then enters a loop that checks the status of the dataset import job every minute using the describe_dataset_import_job API call. If the status is \"ACTIVE\", indicating that the job has completed successfully, the loop is broken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating interaction datajob\n",
    "\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user datajob\n",
    "\n",
    "max_time = time.time() + 6 * 60 * 60  # 6 hours max wait time\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn=user_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(f\"DatasetImportJob: {status}\")\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item datajob\n",
    "\n",
    "\n",
    "max_time = time.time() + 6 * 60 * 60  # 6 hours max wait time\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn=items_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(f\"DatasetImportJob: {status}\")\n",
    "    \n",
    "    if status == \"ACTIVE\":\n",
    "        print(\"Dataset import job completed successfully.\")\n",
    "        break\n",
    "    elif status == \"CREATE FAILED\":\n",
    "        failure_reason = describe_dataset_import_job_response[\"datasetImportJob\"]['failureReason']\n",
    "        print(f\"Dataset import job failed: {failure_reason}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d824510",
   "metadata": {},
   "source": [
    "***Creating Solution and Solution Version***\n",
    "\n",
    "We will be using the \"aws-user-personalization-v2\" recipe which is designed for user personalization tasks. It is a powerful tool for creating personalized recommendations for users based on their interactions with items in a dataset. The recipe uses the User-Personalized Ranking (UPR) algorithm, which is a variation of the Weighted Matrix Factorization (WMF) algorithm. The UPR algorithm is optimized for generating personalized recommendations by focusing on the relative preferences of users rather than their absolute preferences. After choosing the recipe, we must create a solution which is associated to our previous dataset group. The solution may take up to an **_hour_** to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d276648",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-soln-user-personalization\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ee7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fda2de",
   "metadata": {},
   "source": [
    "***Creating and Monitoring Personalize Campaign***\n",
    "\n",
    "We create a campaign in order to serve real-time personalized recommendations to users. The campaign ARN returned by the create_campaign API can be used to invoke the Personalize Runtime API to get recommendations for a specific user. We can also configure the service settings to set a minimum provisioned transactions per second (TPS) for the campaign, which determines the minimum level of traffic the campaign can handle. We also configure the item exploration settings, which can be used to balance exploration of new items versus exploitation of known user preferences. The campaign may take up to an **_15 minutes_** to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183883c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name=\"personalize-recs1\",\n",
    "    solutionVersionArn=solution_version_arn,\n",
    "    minProvisionedTPS=1\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn=campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e55af",
   "metadata": {},
   "source": [
    "## Generating and Saving Personalize Recommendations\n",
    "\n",
    "We first load the interactions data and creates a mapping of item IDs to item names. Next, we use the get_recommendations API from the Personalize Runtime to retrieve personalized recommendations for the selected user, based on the campaign created earlier. The recommended item IDs are then mapped to their corresponding item names using the previously created mapping.Lastly, we iterate through all unique user IDs in the interactions data, retrieving personalized recommendations for each user and storing them in a list of dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51abb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_map = dict(zip(interactions_df['ITEM_ID'].astype(str), interactions_df['PRODUCT_NAME']))\n",
    "user_mapping = interactions_df.set_index('USER_ID')['USERNAME'].to_dict()\n",
    "all_recommendations = []\n",
    "\n",
    "# Group interactions by USER_ID\n",
    "grouped = interactions_df.groupby('USER_ID')\n",
    "\n",
    "for user_id, group in grouped:\n",
    "    get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "        campaignArn=campaign_arn,\n",
    "        userId=str(user_id)\n",
    "    )\n",
    "    \n",
    "    recommendation_list = [item['itemId'] for item in get_recommendations_response['itemList']]\n",
    "    recommendation_names = [items_map.get(item_id, 'Unknown') for item_id in recommendation_list]\n",
    "    latest_timestamp_value = group['TIMESTAMP'].max()\n",
    "    username = user_mapping.get(user_id, 'Unknown')\n",
    "    \n",
    "    # Append the recommendation details for this user\n",
    "    all_recommendations.append({\n",
    "        'USER_ID': user_id,\n",
    "        'Username': username,\n",
    "        'Recommended_Items': recommendation_names[:5],  # Limit to top 5 recommendations\n",
    "        'TIMESTAMP': latest_timestamp_value\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = 'user_recommendations.csv'\n",
    "recommendations_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Recommendations DataFrame saved to {csv_filename}\")\n",
    "\n",
    "print(recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd59b0",
   "metadata": {},
   "source": [
    "Generate a random row from the dataframe to cross match users and their 5 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row = recommendations_df.sample(n=1).iloc[0]\n",
    "\n",
    "user_id = random_row['USER_ID']\n",
    "username = random_row['Username']\n",
    "recommended_items = random_row['Recommended_Items']\n",
    "\n",
    "print(f\"Randomly Selected User ID: {user_id}\")\n",
    "print(f\"Username: {username}\")\n",
    "print(\"Recommended Items:\")\n",
    "for item in recommended_items:\n",
    "    print(f\" - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51efd8",
   "metadata": {},
   "source": [
    "***Storing Personalized Recommendations in Amazon DynamoDB***\n",
    "\n",
    "We create DynamoDB table named if it doesn't already exist, and then insert the personalized recommendations generated in the previous step into the table. The recommendations are stored with the user ID as the hash key and as a dictionary, allowing for efficient retrieval of recommendations for specific users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "table_name = 'user_recommendations'\n",
    "\n",
    "# Create the DynamoDB table if it doesn't exist\n",
    "try:\n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'USER_ID',\n",
    "                'KeyType': 'HASH'  # Partition key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'USER_ID',\n",
    "                'AttributeType': 'S'  # String type for USER_ID\n",
    "            }\n",
    "        ],\n",
    "        BillingMode='PAY_PER_REQUEST'\n",
    "    )\n",
    "    print(f\"Table '{table_name}' created. Status: {table.table_status}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] != 'ResourceInUseException':\n",
    "        print(e)\n",
    "    else:\n",
    "        table = dynamodb.Table(table_name)\n",
    "        print(f\"Table '{table_name}' already exists.\")\n",
    "\n",
    "# Wait until the table is active\n",
    "table.wait_until_exists()\n",
    "\n",
    "# Group recommendations by USER_ID\n",
    "grouped_recommendations = recommendations_df.groupby('USER_ID')\n",
    "\n",
    "# Write the DataFrame to DynamoDB table\n",
    "for user_id, user_recommendations in grouped_recommendations:\n",
    "    with table.batch_writer() as batch:\n",
    "        for index, row in user_recommendations.iterrows():\n",
    "            batch.put_item(Item={\n",
    "                'USER_ID': str(row['USER_ID']),\n",
    "                'Username': row['Username'],\n",
    "                'Recommended_Items': row['Recommended_Items'],\n",
    "                'TIMESTAMP': str(row['TIMESTAMP'])\n",
    "            })\n",
    "\n",
    "print(f\"Recommendations written to DynamoDB table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11948bd0",
   "metadata": {},
   "source": [
    "***Store variables for future use***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store bucket_name\n",
    "%store recommendations_df\n",
    "%store dataset_group_arn\n",
    "%store interaction_schema_arn\n",
    "%store users_schema_arn\n",
    "%store items_schema_arn\n",
    "%store users_dataset_arn\n",
    "%store items_dataset_arn\n",
    "%store interactions_dataset_arn\n",
    "%store role_name\n",
    "%store role_arn\n",
    "%store interactions_df\n",
    "%store user_filename\n",
    "%store solution_version_arn\n",
    "%store solution_arn\n",
    "%store campaign_arn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
